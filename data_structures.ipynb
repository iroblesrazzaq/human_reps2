{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File to create and test data structures for this project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "todo: check that fr rate stuff in neurons, add method for that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mat73\n",
    "from scipy.io import loadmat\n",
    "import re\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Neuron:\n",
    "    \"\"\"\n",
    "    Class for a single Neuron in a single patient\n",
    "    pid: str pid of patient (redundancy maybe but better safe than sorry)\n",
    "    area: str | None  recording area\n",
    "    spikes: list | np.ndarray all spike times (in seconds)\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "        neuron_id: str,\n",
    "        pid: str,\n",
    "        spike_times: np.ndarray,\n",
    "        area: str | None = None,\n",
    "        metadata: dict | None = None):\n",
    "\n",
    "        self.neuron_id = neuron_id\n",
    "        self.pid = pid\n",
    "        self.spike_times = spike_times\n",
    "        self.area = area\n",
    "        self.metadata = metadata\n",
    "    \n",
    "    def firing_rate(self, window: Tuple[float, float] = None) -> float:\n",
    "        \"\"\"\n",
    "        Function to get firing rate of neuron within a certain time period (default whole recording)\n",
    "\n",
    "        times are in seconds\n",
    "        \"\"\"\n",
    "        if window:\n",
    "            spikes = self.spike_times[(self.spike_times >= window[0]) & (self.spike_times <= window[1])]\n",
    "            duration = window[1] - window[0]\n",
    "        else:\n",
    "            spikes = self.spike_times\n",
    "            duration = self.spike_times[-1] - self.spike_times[0]\n",
    "\n",
    "        assert duration > 0, \"Duration < 0, Error\"\n",
    "\n",
    "        return len(spikes) / duration\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatientData:\n",
    "    \"\"\"\n",
    "    Contains all relevant information for a single patient\n",
    "\n",
    "    - movie drift adjusted times with CSV (create new csv to use every time or run code every time -- not expensive so will do second for reproducibility)\n",
    "    - patient info from all exp epochs (start unix, pre/post, etc etc)\n",
    "    - recordings!!  \n",
    "        - dictionary with all neurons and firing times? but also want to be able to filter by brain area\n",
    "\n",
    "\n",
    "    - methods for analysis?\n",
    "        - can be functions for general, not specific to patient\n",
    "        - make analysis class?\n",
    "            - would have functions for heatmaps, decoders, etc?\n",
    "        - these will clutter patient class, I mainly just want all data for a single patient concentrated in one place, easy to use and access\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, pid: str):\n",
    "        # want to load csv, fix correlation issue\n",
    "        # so call function to load csv, multiple times by coefficient, \n",
    "        # get concept onsets from the \n",
    "        self.pid = pid\n",
    "        self.dataloader = Dataloader() # type: ignore\n",
    "\n",
    "        self.neurons: list[Neuron] = self.dataloader.get_all_patient_neurons(self.pid)\n",
    "\n",
    "        self.times_dict = self._get_relative_times() # has everything\n",
    "\n",
    "        self.movie_df = self.times_dict['movie_corrected_concept_times_df'].copy().drop(columns = ['uncorrected_time_sec', 'corrected_time_sec'], axis=1)\n",
    "        \n",
    "        self.preSleep_concepts = self.times_dict['rel_preSleep_concept_vocalizations']\n",
    "        self.postSleep_concepts = self.times_dict['rel_postSleep_concept_vocalizations']\n",
    "\n",
    "\n",
    "    def _get_relative_times(self) -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        Takes unix timing and returns times relative to recording recording start\n",
    "        Adjusts movie onset timing, recall concept vocalization timing to relative to recording start\n",
    "        \n",
    "        \"\"\"\n",
    "        # check that all ts_starts are the same\n",
    "        ts_start = None\n",
    "        for neuron in self.neurons:\n",
    "            if not ts_start:\n",
    "                ts_start = neuron.metadata['ts_start']\n",
    "            else:\n",
    "                if neuron.metadata['ts_start'] != ts_start:\n",
    "                    raise Exception(\"Neuron ts_starts not aligned, something wrong\")\n",
    "        \n",
    "        # now have ts_start verified\n",
    "        unix_times_dict = self.dataloader.get_timing_info(pid=self.pid)\n",
    "        times_dict = {}\n",
    "        for key, val in unix_times_dict.items():\n",
    "            if 'unix' in key:\n",
    "                if isinstance(val, list):\n",
    "                    val = val[0]\n",
    "                times_dict[key] = val # current strat - have all timesin times dict, can make method to remove?\n",
    "                times_dict[key.replace(\"unix\", \"rel\")] = val - ts_start\n",
    "            else:\n",
    "                times_dict[key] = val\n",
    "\n",
    "\n",
    "        df = times_dict[\"movie_corrected_concept_times_df\"]\n",
    "        df[\"rel_corrected_time_sec\"] = df['corrected_time_sec'] + times_dict['movie_start_rel']\n",
    "        times_dict[\"movie_corrected_concept_times_df\"] = df\n",
    "\n",
    "\n",
    "        rel_preSleep_concept_vocalizations = {}\n",
    "        for concept, times_list in times_dict['preSleep_concept_vocalizations'].items():\n",
    "            rel = times_dict['preSleep_recall_start_rel']\n",
    "            rel_preSleep_concept_vocalizations[concept] = [t + rel for t in times_list]\n",
    "            times_dict['rel_preSleep_concept_vocalizations'] = rel_preSleep_concept_vocalizations\n",
    "        \n",
    "        rel_postSleep_concept_vocalizations = {}\n",
    "        for concept, times_list in times_dict['postSleep_concept_vocalizations'].items():\n",
    "            rel = times_dict['postSleep_recall_start_rel']\n",
    "            rel_postSleep_concept_vocalizations[concept] = [t + rel for t in times_list]\n",
    "            times_dict['rel_postSleep_concept_vocalizations'] = rel_postSleep_concept_vocalizations\n",
    "\n",
    "        return times_dict\n",
    "    \n",
    "    def _bin_time(self, time: float, neurons: list[Neuron], bin_size=1.0, offset: float = 0.2) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        returns the firing rate of a list of neurons for a certain window\n",
    "            - does not track individual neurons consistently\n",
    "            - can add functionality to do so by adding neuron id dimension?\n",
    "            - not necessary as of now\n",
    "\n",
    "\n",
    "        input: \n",
    "            time (float): time that we want to bin\n",
    "            offset (float): offset of bin start from time, default is 0.2 seconds\n",
    "            bin_size (float): size of bin in seconds\n",
    "            neurons: list of neurons that we want to bin at this time\n",
    "\n",
    "        returns: np.ndarray of shape (n_neurons)\n",
    "        \"\"\"\n",
    "        assert isinstance(neurons, list)\n",
    "        assert isinstance(neurons[0], Neuron)\n",
    "\n",
    "        left_edge = time + offset\n",
    "        right_edge = left_edge + bin_size\n",
    "\n",
    "        firing_rates = np.zeros(len(neurons), dtype=float)\n",
    "\n",
    "        for i, neuron in enumerate(neurons):\n",
    "            firing_rates[i] = neuron.firing_rate(window=(left_edge, right_edge))\n",
    "        return firing_rates\n",
    "    \n",
    "    def _bin_times(self, times: List[float], neurons: List[Neuron], bin_size=1.0, offset=0.2) -> np.ndarray:\n",
    "        \"\"\"Calls bin time on times, returns array of shape (neurons, time) -> each columns is firing rate in a certain time window\"\"\"\n",
    "        if not isinstance(times, list):\n",
    "            raise TypeError(\"'times' must be a list.\")\n",
    "\n",
    "        all_binned_rates = []\n",
    "        for time in times:\n",
    "            binned_rates = self._bin_time(time=time, neurons=neurons, bin_size=bin_size, offset=offset)\n",
    "            all_binned_rates.append(binned_rates)\n",
    "\n",
    "        return np.array(all_binned_rates) # get (n_times, n_neurons)\n",
    "    \n",
    "    def exclusive_movie_times(self, c1: str, c2: str, time_present: float = 1.0) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Takes two concepts in movie and returns all times for c1 exclusive onsets wrt c2:\n",
    "        c1 absent to present, present for at least one second, and c2 absent whole time\n",
    "\n",
    "        NOTE: for concept decoding, need to call both ways\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        if c1 not in self.movie_df.columns or c2 not in self.movie_df.columns:\n",
    "            raise ValueError(\"Both concepts must be valid columns in movie_df.\")\n",
    "\n",
    "        df = self.movie_df\n",
    "\n",
    "        c1_onsets = []\n",
    "        for i in range(1, len(df)):\n",
    "            # 1. Check for c1 transition from 0 to 1\n",
    "            if df[c1].iloc[i - 1] == 0 and df[c1].iloc[i] == 1:\n",
    "                # 2. Check if c2 is 0 at the onset time\n",
    "                if df[c2].iloc[i] == 0 and df[c2].iloc[i - 1] == 0:\n",
    "                    onset_time = df['rel_corrected_time_sec'].iloc[i]\n",
    "                    next_second_end = onset_time + time_present\n",
    "\n",
    "                    # 3. Find the range of indices for the next second\n",
    "                    next_second_indices = df.index[\n",
    "                        (df['rel_corrected_time_sec'] >= onset_time) &\n",
    "                        (df['rel_corrected_time_sec'] < next_second_end)\n",
    "                    ]\n",
    "                    \n",
    "                    # 4. Check if c1 is *always* 1 and c2 is *always* 0 within the next second\n",
    "                    if (all(df[c1].iloc[next_second_indices] == 1) and\n",
    "                        all(df[c2].iloc[next_second_indices] == 0)):\n",
    "                        c1_onsets.append(onset_time)\n",
    "\n",
    "        return np.array(c1_onsets)\n",
    "\n",
    "    def exclusive_recall_times(self, c1: str, c2: str, epoch: str, buffer=2.0) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Finds all times where c1 is recalled and c2 is not recalled within \n",
    "        the buffer on either side of the c1 recall time\n",
    "        \n",
    "        Input: \n",
    "            epoch: str - preSleep or postSleep\n",
    "\n",
    "        NOTE: for concept decoding, need to call both ways\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def get_concept_data(self, c1: str, c2: str, epoch: str):\n",
    "        \"\"\"\n",
    "        Concerns: how to filter neurons: option for brain area, potentially neuron id?\n",
    "\n",
    "        returns the concept bins for two concepts\n",
    "        what do we do with movie \n",
    "        \"\"\"\n",
    "        \n",
    "\n",
    "        if epoch == 'movie':\n",
    "            c1_times = list(self.exclusive_movie_times(c1=c1, c2=c2))\n",
    "            c2_times = list(self.exclusive_movie_times(c1=c2, c2=c1))\n",
    "\n",
    "            c1_bins = self._bin_times(c1_times, neurons=self.neurons) # use default 1s bin 0.2s offset\n",
    "            c2_bins = self._bin_times(c2_times, neurons=self.neurons)\n",
    "\n",
    "\n",
    "# TODO: finish this lol\n",
    "\n",
    "            return c1_bins, c2_bins # each row is a response\n",
    "\n",
    "        elif epoch == 'preSleep_recall':\n",
    "\n",
    "            raise NotImplementedError\n",
    "        elif epoch == 'postSleep_recall':\n",
    "\n",
    "            raise NotImplementedError\n",
    "\n",
    "        else:\n",
    "            raise Exception(\"invalid epoch name\")\n",
    "\n",
    "    def filter_neurons_by_area(self, areas: List[str]) -> List[Neuron]:\n",
    "        \"\"\"\n",
    "        returns list of neurons with areas inputted only\n",
    "        \"\"\"\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "brainstorming of patient class, has good thoughts\n",
    "\n",
    "\n",
    "    Contains all relevant information for a single patient\n",
    "\n",
    "    - movie drift adjusted times with CSV (create new csv to use every time or run code every time -- not expensive so will do second for reproducibility)\n",
    "    - patient info from all exp epochs (start unix, pre/post, etc etc)\n",
    "    - recordings!!  \n",
    "        - dictionary with all neurons and firing times? but also want to be able to filter by brain area\n",
    "\n",
    "\n",
    "    - methods for analysis?\n",
    "        - can be functions for general, not specific to patient\n",
    "        - make analysis class?\n",
    "            - would have functions for heatmaps, decoders, etc?\n",
    "        - these will clutter patient class, I mainly just want all data for a single patient concentrated in one place, easy to use and access\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataloader:\n",
    "    \"\"\"Class to contain functions to load data\"\"\"\n",
    "\n",
    "\n",
    "    def parse_filename(self, filename):\n",
    "        base = filename.split('-')[-1].replace('.mat', '')\n",
    "\n",
    "        parsed = filename.replace('.mat', '').split('-')\n",
    "        if len(parsed) == 2:  # Normal case like GA2-RAH7\n",
    "            base = parsed[-1]\n",
    "        elif len(parsed) == 3:  # Case with hyphenated area like GA3-RSUB-PHG1\n",
    "            base = '-'.join(parsed[1:])  # Join with hyphen to preserve structure\n",
    "        else:\n",
    "            return (filename.replace('.mat', ''), None)\n",
    "\n",
    "        match = re.match(r'(.*?[-]?\\w+?)(\\d+)$', base)\n",
    "        if match:\n",
    "            area_name = match.group(1)  # Group 1 contains everything before the numbers\n",
    "            channel_num = match.group(2)  # Group 2 contains the numbers\n",
    "            return base, area_name\n",
    "        return (base, None) # None for no areaname\n",
    "    \n",
    "\n",
    "    def _get_neurons_from_mat(self, file_path, pid):\n",
    "        \"\"\"\n",
    "        Load spike data from .mat file, handling different MATLAB file versions\n",
    "\n",
    "        Return instances of the Neuron class, adding spike data to each one\n",
    "        \"\"\"\n",
    "        try:\n",
    "            data = loadmat(file_path)\n",
    "        except (NotImplementedError, TypeError):\n",
    "            data = mat73.loadmat(file_path)\n",
    "        \n",
    "        # Extract cluster_class data\n",
    "        cluster_class = data['cluster_class']\n",
    "        \n",
    "        # Extract timestampsStart\n",
    "        ts_start = data[\"timestampsStart\"]\n",
    "        if ts_start.shape == ():\n",
    "            ts_start = float(ts_start)\n",
    "        else:\n",
    "            ts_start = float(ts_start[0][0])\n",
    "\n",
    "        filename = file_path.split('/')[-1]\n",
    "        base, area_name = self.parse_filename(filename)\n",
    "        neurons = []\n",
    "        unique_clusters = np.unique(cluster_class[:, 0])\n",
    "        for cluster_id in unique_clusters:\n",
    "            mask = cluster_class[:, 0] == cluster_id\n",
    "            spike_times = cluster_class[mask, 1]\n",
    "\n",
    "            neurons.append(Neuron(\n",
    "                neuron_id=f\"{base}-{int(cluster_id)}\",\n",
    "                pid = pid,\n",
    "                spike_times=spike_times,\n",
    "                area=area_name,\n",
    "                metadata={'ts_start': ts_start}\n",
    "                ))\n",
    "\n",
    "        return neurons\n",
    "    \n",
    "    def get_all_patient_neurons(self, pid, base_dir=\"./Data\"):\n",
    "        neurons = []\n",
    "        for patient_dir in os.listdir(base_dir): # lists 566_movie paradigm, etc dirs\n",
    "            patient_dict_name = f\"{patient_dir.replace('_MovieParadigm', '')}_files\"\n",
    "\n",
    "            if pid in patient_dir: # we have the correct patient id\n",
    "                for exp_dir in os.listdir(os.path.join(base_dir, patient_dir)):\n",
    "                    if len(exp_dir.split('-')) > 2: # then we have our exp-5-6-7 pattern directory with spiking files\n",
    "                        for file in os.listdir(os.path.join(base_dir, patient_dir, exp_dir, 'CSC_micro_spikes')):\n",
    "                            file_path = os.path.join(base_dir, patient_dir, exp_dir, 'CSC_micro_spikes', file)\n",
    "                            neurons += self._get_neurons_from_mat(file_path=file_path, pid=pid)\n",
    "        return neurons # list of all neurons\n",
    "    \n",
    "    def _timing_info(self, pid, base_dir=\"./Data\"):\n",
    "        res_dict = {}\n",
    "        for pdir in os.listdir(base_dir):\n",
    "            \n",
    "            if pid in pdir: # relevant directory\n",
    "                #print(f\"pdir: {pdir}\")\n",
    "                \n",
    "                for exp_dir in os.listdir(os.path.join(base_dir, pdir)):\n",
    "                    if len(exp_dir.split('-')) == 2: # Exp-K directory\n",
    "                        for file in os.listdir(os.path.join(base_dir, pdir, exp_dir, 'Audio')):\n",
    "                            if 'FR1' in file:\n",
    "                                with open(os.path.join(base_dir, pdir, exp_dir, 'Audio', file)) as f:\n",
    "                                    data = json.load(f)\n",
    "                                    res_dict['preSleep_concept_vocalizations'] = data\n",
    "                            elif 'FR2' in file:\n",
    "                                with open(os.path.join(base_dir, pdir, exp_dir, 'Audio', file)) as f:\n",
    "                                    data = json.load(f)\n",
    "                                    res_dict['postSleep_concept_vocalizations'] = data\n",
    "                            elif \"audio_movie_start\" in file:\n",
    "                                with open(os.path.join(base_dir, pdir, exp_dir, 'Audio', file)) as f:\n",
    "                                    data = json.load(f)\n",
    "                                    res_dict['movie_timing_info'] = data\n",
    "                            elif \"audio_recall_timing\" in file and 'pre' in file:\n",
    "                                with open(os.path.join(base_dir, pdir, exp_dir, 'Audio', file)) as f:\n",
    "                                    data = json.load(f)\n",
    "                                    res_dict['preSleep_recall_timing'] = data\n",
    "                            elif \"audio_recall_timing\" in file and 'post' in file:\n",
    "                                with open(os.path.join(base_dir, pdir, exp_dir, 'Audio', file)) as f:\n",
    "                                    data = json.load(f)\n",
    "                                    res_dict['postSleep_recall_timing'] = data\n",
    "        res_dict['concept_csv_path'] = base_dir + \"/40m_act_24_S06E01_30fps_character_frames.csv\"\n",
    "        return res_dict\n",
    "\n",
    "    def _extract_relevant_timing_info(self, pid, res_dict):\n",
    "        relevant_timing = {}\n",
    "        for key, info in res_dict.items():\n",
    "            if key == \"preSleep_concept_vocalizations\":\n",
    "                if info['pID'] == int(pid): # check for correct patient, sanity check\n",
    "                    preSleep_concept_vocalizations = {}\n",
    "                    for field, val in info.items():\n",
    "                        if isinstance(val, list):\n",
    "                            ms_to_secs = []\n",
    "                            for time in val:\n",
    "                                ms_to_secs.append(time/1000)\n",
    "                            preSleep_concept_vocalizations[field] = ms_to_secs\n",
    "                    relevant_timing['preSleep_concept_vocalizations'] = preSleep_concept_vocalizations# need to divide by 1000 for ms to s conversion\n",
    "\n",
    "\n",
    "            if key == \"postSleep_concept_vocalizations\":\n",
    "                if info['pID'] == int(pid):\n",
    "                    postSleep_concept_vocalizations = {}\n",
    "                    for field, val in info.items():\n",
    "                        if isinstance(val, list):\n",
    "                            ms_to_secs = []\n",
    "                            for time in val:\n",
    "                                ms_to_secs.append(time/1000)\n",
    "                            postSleep_concept_vocalizations[field] = ms_to_secs\n",
    "                    relevant_timing['postSleep_concept_vocalizations'] = postSleep_concept_vocalizations # need to divide by 1000 for ms to s conversion\n",
    "\n",
    "            if key == \"movie_timing_info\":\n",
    "                relevant_timing['movie_drift_factor'] = info[\"drift_correction_multiplier\"]\n",
    "                relevant_timing['movie_start_unix'] = info['start_unix']\n",
    "\n",
    "            if key == \"preSleep_recall_timing\":\n",
    "                relevant_timing['preSleep_recall_start_unix'] = info['start_unix']\n",
    "                relevant_timing['preSleep_recall_end_unix'] = info['end_unix']\n",
    "\n",
    "            if key == \"postSleep_recall_timing\":\n",
    "                relevant_timing['postSleep_recall_start_unix'] = info['start_unix']\n",
    "                relevant_timing['postSleep_recall_end_unix'] = info['end_unix']\n",
    "\n",
    "            if key == \"concept_csv_path\": # if concept csv we will read from that path\n",
    "                print(info)\n",
    "                concept_csv = pd.read_csv(info)\n",
    "                drift = relevant_timing['movie_drift_factor']\n",
    "                concept_csv['corrected_time_sec'] = concept_csv['uncorrected_time_sec'] * drift\n",
    "\n",
    "                relevant_timing['movie_corrected_concept_times_df'] = concept_csv\n",
    "\n",
    "        return relevant_timing\n",
    "    \n",
    "    def get_timing_info(self, pid) -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        Public method for class, calls _timing_info and _extract methods\n",
    "        \n",
    "        Returns: dict[str: str]\n",
    "        \"\"\"\n",
    "        res = self._timing_info(pid=pid)\n",
    "        return self._extract_relevant_timing_info(pid=pid, res_dict=res)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "            \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Data/40m_act_24_S06E01_30fps_character_frames.csv\n"
     ]
    }
   ],
   "source": [
    "p563 = PatientData('563')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Frame', 'A.Amar', 'A.Fayed', 'B.Buchanan', 'C.Manning', 'C.OBrian',\n",
       "       'J.Bauer', 'J.Wallace', 'K.Hayes', 'M.OBrian', 'M.Pressman',\n",
       "       'Minor Char', 'N.Yassir', 'No Characters', 'R.Wallace', 'S.Wallace',\n",
       "       'T.Lennox', 'W.Palmer', 'rel_corrected_time_sec'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.movie_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[241], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m c1_bins, c2_bins \u001b[38;5;241m=\u001b[39m \u001b[43mp563\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_concept_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mA.Amar\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mB.Buchanan\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmovie\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[233], line 183\u001b[0m, in \u001b[0;36mPatientData.get_concept_data\u001b[0;34m(self, c1, c2, epoch)\u001b[0m\n\u001b[1;32m    180\u001b[0m             c1_times \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexclusive_movie_times(c1\u001b[38;5;241m=\u001b[39mc1, c2\u001b[38;5;241m=\u001b[39mc2))\n\u001b[1;32m    181\u001b[0m             c2_times \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexclusive_movie_times(c1\u001b[38;5;241m=\u001b[39mc2, c2\u001b[38;5;241m=\u001b[39mc1))\n\u001b[0;32m--> 183\u001b[0m             c1_bins \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bin_times\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc1_times\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneurons\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mneurons\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# use default 1s bin 0.2s offset\u001b[39;00m\n\u001b[1;32m    184\u001b[0m             c2_bins \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bin_times(c2_times, neurons\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneurons)\n\u001b[1;32m    187\u001b[0m \u001b[38;5;66;03m# TODO: finish this lol\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[233], line 117\u001b[0m, in \u001b[0;36mPatientData._bin_times\u001b[0;34m(self, times, neurons, bin_size, offset)\u001b[0m\n\u001b[1;32m    115\u001b[0m all_binned_rates \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m time \u001b[38;5;129;01min\u001b[39;00m times:\n\u001b[0;32m--> 117\u001b[0m     binned_rates \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bin_time\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneurons\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneurons\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbin_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbin_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m     all_binned_rates\u001b[38;5;241m.\u001b[39mappend(binned_rates)\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(all_binned_rates)\n",
      "Cell \u001b[0;32mIn[233], line 107\u001b[0m, in \u001b[0;36mPatientData._bin_time\u001b[0;34m(self, time, neurons, bin_size, offset)\u001b[0m\n\u001b[1;32m    104\u001b[0m firing_rates \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mlen\u001b[39m(neurons), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m)\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, neuron \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(neurons):\n\u001b[0;32m--> 107\u001b[0m     firing_rates[i] \u001b[38;5;241m=\u001b[39m \u001b[43mneuron\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfiring_rate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwindow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mleft_edge\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright_edge\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m firing_rates\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object is not callable"
     ]
    }
   ],
   "source": [
    "c1_bins, c2_bins = p563.get_concept_data(c1='A.Amar', c2='B.Buchanan', epoch='movie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[237], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mp563\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bin_time\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m485.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneurons\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mp563\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mneurons\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[233], line 107\u001b[0m, in \u001b[0;36mPatientData._bin_time\u001b[0;34m(self, time, neurons, bin_size, offset)\u001b[0m\n\u001b[1;32m    104\u001b[0m firing_rates \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mlen\u001b[39m(neurons), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m)\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, neuron \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(neurons):\n\u001b[0;32m--> 107\u001b[0m     firing_rates[i] \u001b[38;5;241m=\u001b[39m \u001b[43mneuron\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfiring_rate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwindow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mleft_edge\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright_edge\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m firing_rates\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object is not callable"
     ]
    }
   ],
   "source": [
    "p563._bin_time(time=485.0, neurons=p563.neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
