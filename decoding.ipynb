{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "notebook for decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_structures import PatientData\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from typing import Tuple\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Data/40m_act_24_S06E01_30fps_character_frames.csv\n",
      "./Data/40m_act_24_S06E01_30fps_character_frames.csv\n"
     ]
    }
   ],
   "source": [
    "p566 = PatientData(pid='566')\n",
    "p563 = PatientData(pid='563')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DecodingResult:\n",
    "    \"\"\"Container for decoding results and metrics\"\"\"\n",
    "    accuracy: float\n",
    "    roc_auc: float\n",
    "    train_samples: Dict[str, int]  # Number of samples for each concept in training\n",
    "    test_samples: Dict[str, int]   # Number of samples for each concept in testing\n",
    "    predictions: np.ndarray\n",
    "    true_labels: np.ndarray\n",
    "    classifier: BaseEstimator\n",
    "    data: Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConceptDecoder:\n",
    "    \n",
    "    \"\"\"\n",
    "    Handles decoding for a single concept pair\n",
    "\n",
    "    - design choice - will call dataset method in each decoder call?\n",
    "\n",
    "    - problem is that generally we want an object associated with one dataset - this would require an input for pseudo or not\n",
    "    in the class instantiation. however, we want fine control over pseudopops parameters, so this is less good.\n",
    "    one potential solution is a params* dict, but thats complicated. \n",
    "\n",
    "    for consistent stuff\n",
    "\n",
    "    maybe separate classes - instantiate dataset, get training into dict, input training dict into concept decoder?\n",
    "\n",
    "    - add method for PCA visualization in 2D/3D\n",
    "    \"\"\"\n",
    "    def __init__(self, patient_data: PatientData, c1: str, c2: str, epoch: str, classifier: BaseEstimator = LinearSVC(), dataset: ConceptPairDataset = None, standardize: bool=False):\n",
    "        self.patient_data = patient_data\n",
    "        self.c1 = c1\n",
    "        self.c2 = c2\n",
    "        self.epoch = epoch\n",
    "        self.classifier = classifier\n",
    "\n",
    "        self.scaler = StandardScaler() if standardize else None\n",
    "        self.metrics = {}\n",
    "\n",
    "    \n",
    "        if not dataset:\n",
    "            self.dataset = ConceptPairDataset( #type: ignore\n",
    "                patient_data=self.patient_data,\n",
    "                concept_pair=(self.c1, self.c2),\n",
    "                epoch=self.epoch, \n",
    "                #min_samples = 10\n",
    "            )\n",
    "        else:\n",
    "            self.dataset = dataset\n",
    "\n",
    "    def decode(self, test_size: float = 0.3) -> DecodingResult: \n",
    "        \"\"\"\n",
    "        Performs decoding on the concept pair using normal dataset\n",
    "        \n",
    "        Args:\n",
    "            test_size: Fraction of data to use for testing\n",
    "            \n",
    "        Returns:\n",
    "            DecodingResult containing metrics and predictions\n",
    "        \"\"\"\n",
    "        data_dict, info = self.dataset.create_dataset_normal(test_size=test_size)\n",
    "\n",
    "\n",
    "        X_train = data_dict['X_train']\n",
    "        X_test = data_dict['X_test']\n",
    "        y_train = data_dict['y_train']\n",
    "        y_test = data_dict['y_test']\n",
    "\n",
    "        if self.scaler:\n",
    "            X_train = self.scaler.fit_transform(X_train)\n",
    "            X_test = self.scaler.transform(X_test)\n",
    "\n",
    "        self.classifier.fit(X_train, y_train)\n",
    "        \n",
    "        # Get predictions\n",
    "        y_pred = self.classifier.predict(X_test)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred)\n",
    "        \n",
    "        train_samples = {\n",
    "            self.c1: np.sum(y_train == 0),\n",
    "            self.c2: np.sum(y_train == 1)\n",
    "        }\n",
    "        test_samples = {\n",
    "            self.c1: np.sum(y_test == 0),\n",
    "            self.c2: np.sum(y_test == 1)\n",
    "        }\n",
    "\n",
    "        return DecodingResult(\n",
    "            accuracy=accuracy,\n",
    "            roc_auc=roc_auc,\n",
    "            train_samples=train_samples,\n",
    "            test_samples=test_samples,\n",
    "            predictions=y_pred,\n",
    "            true_labels=y_test,\n",
    "            classifier=self.classifier,\n",
    "            data=data_dict\n",
    "        )\n",
    "\n",
    "    def decode_pseudo(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConceptPairDataset():\n",
    "    \"\"\"\n",
    "    Class to turn both concept bins - np.ndarrays shape (n_onsets, n_neurons) (each row is a response) into dataset with \n",
    "\n",
    "    2 methods - one with psuedopopulations\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, patient_data: PatientData, concept_pair: Tuple[str, str], \n",
    "                 epoch: str, min_samples: int = 10):\n",
    "        self.patient_data = patient_data\n",
    "        self.c1, self.c2 = concept_pair\n",
    "        self.epoch = epoch\n",
    "        self.min_samples = min_samples\n",
    "\n",
    "    def create_dataset_normal(self, test_size = 0.3):\n",
    "        \"\"\"\n",
    "        Method to create dataset without pseudopops, liable to make unbalanced dataset\n",
    "\n",
    "        Returns X_train, X_test, y_train, y_test, info: dict\n",
    "        \"\"\"\n",
    "        c1_data, c2_data = self.patient_data.get_concept_data(c1=self.c1, c2=self.c2, epoch=self.epoch)\n",
    "\n",
    "        print(f\"c1 shape: {c1_data.shape[0]}, c2 shape: {c2_data.shape[0]}\")\n",
    "\n",
    "        if len(c1_data) < self.min_samples or len(c2_data) < self.min_samples:\n",
    "            raise ValueError(f\"Insufficient samples for {self.concept1} vs {self.concept2}\")\n",
    "\n",
    "        X = np.vstack([c1_data, c2_data])\n",
    "        y = np.concatenate([np.zeros(len(c1_data)), np.ones(len(c2_data))])\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "\n",
    "        info = {} #for any extra stuff we wanna pass through\n",
    "        res_dict = {\n",
    "            'X_train': X_train, 'X_test': X_test, 'y_test': y_test, 'y_train': y_train\n",
    "        }\n",
    "\n",
    "        return res_dict, info\n",
    "\n",
    "    def create_dataset_pseudo(self):\n",
    "        raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing playground\n",
    "\n",
    "\n",
    ":)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6],\n",
       "       [7, 8, 9]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1, 2, 3])\n",
    "b = np.array([[4, 5, 6], [7, 8, 9]])\n",
    "x = np.vstack([a, b])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = ConceptPairDataset(p566, ('A.Amar', 'B.Buchanan'), epoch='movie')\n",
    "z1 = ConceptPairDataset(p563, ('A.Amar', 'B.Buchanan'), epoch='movie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c1 shape: 20, c2 shape: 68\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = z.create_dataset_normal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61, 169)\n",
      "(27, 169)\n",
      "(61,)\n",
      "(27,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Data/40m_act_24_S06E01_30fps_character_frames.csv\n",
      "c1 shape: 20, c2 shape: 68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ismaelrobles-razzaq/Desktop/research/.venv/lib/python3.11/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "p563 = PatientData(pid='563')\n",
    "decoder = ConceptDecoder(patient_data=p563, c1='A.Amar', c2='B.Buchanan', epoch='movie')\n",
    "res = decoder.decode()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7407407407407407"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
