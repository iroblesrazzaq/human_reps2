{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "notebook for decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_structures import PatientData\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from typing import Tuple\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Data/40m_act_24_S06E01_30fps_character_frames.csv\n",
      "./Data/40m_act_24_S06E01_30fps_character_frames.csv\n"
     ]
    }
   ],
   "source": [
    "p566 = PatientData(pid='566')\n",
    "p563 = PatientData(pid='563')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DecodingResult:\n",
    "    \"\"\"Container for decoding results and metrics\"\"\"\n",
    "    test_accuracy: float\n",
    "    train_accuracy: float\n",
    "    test_roc_auc: float\n",
    "    train_roc_auc: float\n",
    "    train_samples: Dict[str, int]  # Number of samples for each concept in training\n",
    "    test_samples: Dict[str, int]   # Number of samples for each concept in testing\n",
    "    predictions: np.ndarray\n",
    "    true_labels: np.ndarray\n",
    "    classifier: BaseEstimator\n",
    "    data: Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConceptDecoder:\n",
    "    \n",
    "    \"\"\"\n",
    "    Handles decoding for a single concept pair\n",
    "\n",
    "    - design choice - will call dataset method in each decoder call?\n",
    "\n",
    "    - problem is that generally we want an object associated with one dataset - this would require an input for pseudo or not\n",
    "    in the class instantiation. however, we want fine control over pseudopops parameters, so this is less good.\n",
    "    one potential solution is a params* dict, but thats complicated. \n",
    "\n",
    "    for consistent stuff\n",
    "\n",
    "    maybe separate classes - instantiate dataset, get training into dict, input training dict into concept decoder?\n",
    "\n",
    "    - add method for PCA visualization in 2D/3D\n",
    "    \"\"\"\n",
    "    def __init__(self, patient_data: PatientData, c1: str, c2: str, epoch: str, classifier: BaseEstimator = LinearSVC(), dataset: ConceptPairDataset = None, standardize: bool=False):\n",
    "        self.patient_data = patient_data\n",
    "        self.c1 = c1\n",
    "        self.c2 = c2\n",
    "        self.epoch = epoch\n",
    "        self.classifier = classifier\n",
    "\n",
    "        self.scaler = StandardScaler() if standardize else None\n",
    "        self.metrics = {}\n",
    "\n",
    "    \n",
    "        if not dataset:\n",
    "            self.dataset = ConceptPairDataset( #type: ignore\n",
    "                patient_data=self.patient_data,\n",
    "                concept_pair=(self.c1, self.c2),\n",
    "                epoch=self.epoch, \n",
    "                min_samples = 20\n",
    "            )\n",
    "        else:\n",
    "            self.dataset = dataset\n",
    "\n",
    "    def decode(self, test_size: float = 0.3) -> DecodingResult: \n",
    "        \"\"\"\n",
    "        Performs decoding on the concept pair using normal dataset\n",
    "        \n",
    "        Args:\n",
    "            test_size: Fraction of data to use for testing\n",
    "            \n",
    "        Returns:\n",
    "            DecodingResult containing metrics and predictions\n",
    "        \"\"\"\n",
    "        try:\n",
    "            data_dict, info = self.dataset.create_dataset_normal(test_size=test_size)\n",
    "        except ValueError as e:\n",
    "            print(f\"Skipping concept pair {self.c1}, {self.c2}: {e}\") # Inform user of skipped pair and reason\n",
    "            return None # Return None to indicate decoding failure for this pair\n",
    "\n",
    "\n",
    "        X_train = data_dict['X_train']\n",
    "        X_test = data_dict['X_test']\n",
    "        y_train = data_dict['y_train']\n",
    "        y_test = data_dict['y_test']\n",
    "\n",
    "        if self.scaler:\n",
    "            X_train = self.scaler.fit_transform(X_train)\n",
    "            X_test = self.scaler.transform(X_test)\n",
    "\n",
    "        self.classifier.fit(X_train, y_train)\n",
    "        \n",
    "        # Get predictions\n",
    "        y_train_pred = self.classifier.predict(X_train)\n",
    "        y_pred = self.classifier.predict(X_test)\n",
    "\n",
    "        # Calculate metrics for train and test\n",
    "        train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "        test_accuracy = accuracy_score(y_test, y_pred)\n",
    "        train_roc_auc = roc_auc_score(y_train, y_train_pred) # or use decision_function for prob based ROC AUC if needed\n",
    "        test_roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "        \n",
    "        train_samples = {\n",
    "            self.c1: np.sum(y_train == 0),\n",
    "            self.c2: np.sum(y_train == 1)\n",
    "        }\n",
    "        test_samples = {\n",
    "            self.c1: np.sum(y_test == 0),\n",
    "            self.c2: np.sum(y_test == 1)\n",
    "        }\n",
    "\n",
    "        return DecodingResult(\n",
    "            train_accuracy=train_accuracy,\n",
    "            train_roc_auc=train_roc_auc,\n",
    "            test_accuracy=test_accuracy,\n",
    "            test_roc_auc=test_roc_auc,\n",
    "            train_samples=train_samples,\n",
    "            test_samples=test_samples,\n",
    "            predictions=y_pred,\n",
    "            true_labels=y_test,\n",
    "            classifier=self.classifier,\n",
    "            data=data_dict\n",
    "        )\n",
    "\n",
    "    def decode_pseudo(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConceptPairDataset():\n",
    "    \"\"\"\n",
    "    Class to turn both concept bins - np.ndarrays shape (n_onsets, n_neurons) (each row is a response) into dataset with \n",
    "\n",
    "    2 methods - one with psuedopopulations\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, patient_data: PatientData, concept_pair: Tuple[str, str], \n",
    "                 epoch: str, min_samples: int = 10):\n",
    "        self.patient_data = patient_data\n",
    "        self.c1, self.c2 = concept_pair\n",
    "        self.epoch = epoch\n",
    "        self.min_samples = min_samples\n",
    "\n",
    "    def create_dataset_normal(self, test_size = 0.3):\n",
    "        \"\"\"\n",
    "        Method to create dataset without pseudopops, liable to make unbalanced dataset\n",
    "\n",
    "        Returns X_train, X_test, y_train, y_test, info: dict\n",
    "        \"\"\"\n",
    "        c1_data, c2_data = self.patient_data.get_concept_data(c1=self.c1, c2=self.c2, epoch=self.epoch)\n",
    "\n",
    "        print(f\"c1 shape: {c1_data.shape[0]}, c2 shape: {c2_data.shape[0]}\")\n",
    "\n",
    "        if len(c1_data) < self.min_samples or len(c2_data) < self.min_samples:\n",
    "            raise ValueError(f\"Insufficient samples for {self.c1} vs {self.c2}\")\n",
    "\n",
    "        X = np.vstack([c1_data, c2_data])\n",
    "        y = np.concatenate([np.zeros(len(c1_data)), np.ones(len(c2_data))])\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "\n",
    "        info = {} #for any extra stuff we wanna pass through\n",
    "        res_dict = {\n",
    "            'X_train': X_train, 'X_test': X_test, 'y_test': y_test, 'y_train': y_train\n",
    "        }\n",
    "\n",
    "        return res_dict, info\n",
    "\n",
    "    def create_dataset_pseudo(self):\n",
    "        raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecodingResultsManager:\n",
    "    \"\"\"\n",
    "    Manages decoding results for multiple concept pairs for a single patient and epoch.\n",
    "    \"\"\"\n",
    "    def __init__(self, patient_data: PatientData, concept_pairs: List[Tuple[str, str]], epoch: str, classifier: BaseEstimator = LinearSVC(), standardize: bool = False):\n",
    "        self.patient_data = patient_data\n",
    "        self.concept_pairs = concept_pairs\n",
    "        self.epoch = epoch\n",
    "        self.classifier = classifier # Default classifier for all decoders, can be overridden\n",
    "        self.standardize = standardize # Default standardization for all decoders\n",
    "        self.results: Dict[Tuple[str, str], DecodingResult] = {} # Store results here, key is concept pair\n",
    "\n",
    "    def run_decoding_for_pairs(self) -> None:\n",
    "        \"\"\"\n",
    "        Runs decoding for all concept pairs provided in the constructor.\n",
    "        Stores the DecodingResult in the self.results dictionary.\n",
    "        \"\"\"\n",
    "        for c1, c2 in self.concept_pairs:\n",
    "            decoder = ConceptDecoder(\n",
    "                patient_data=self.patient_data,\n",
    "                c1=c1,\n",
    "                c2=c2,\n",
    "                epoch=self.epoch,\n",
    "                classifier=self.classifier,\n",
    "                standardize=self.standardize\n",
    "            )\n",
    "            result = decoder.decode()\n",
    "            if result is not None: # Only store if decode was successful (not None)\n",
    "                self.results[(c1, c2)] = result\n",
    "\n",
    "    def plot_train_test_performance_heatmap(self, metric='test_roc_auc', figsize=(20, 10)):\n",
    "        \"\"\"\n",
    "        Generates and displays a combined heatmap of training and testing performance for all concept pairs.\n",
    "        Metrics can be 'test_accuracy', 'train_accuracy', 'test_roc_auc', 'train_roc_auc'.\n",
    "        \"\"\"\n",
    "        concepts = sorted(list(set([c for pair in self.concept_pairs for c in pair])))\n",
    "        n_concepts = len(concepts)\n",
    "        train_matrix = np.full((n_concepts, n_concepts), np.nan)\n",
    "        test_matrix = np.full((n_concepts, n_concepts), np.nan)\n",
    "\n",
    "        concept_to_idx = {concept: i for i, concept in enumerate(concepts)}\n",
    "\n",
    "        for concept_pair, result in self.results.items():\n",
    "            if result is not None:\n",
    "                c1, c2 = concept_pair\n",
    "                i, j = concept_to_idx[c1], concept_to_idx[c2]\n",
    "\n",
    "                # Fix: Use the full attribute names\n",
    "                if 'roc_auc' in metric:\n",
    "                    train_value = result.train_roc_auc\n",
    "                    test_value = result.test_roc_auc\n",
    "                else:  # accuracy\n",
    "                    train_value = result.train_accuracy\n",
    "                    test_value = result.test_accuracy\n",
    "\n",
    "                train_matrix[i, j] = train_value\n",
    "                train_matrix[j, i] = train_value\n",
    "                test_matrix[i, j] = test_value\n",
    "                test_matrix[j, i] = test_value\n",
    "\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)\n",
    "\n",
    "        heatmap_params = {\n",
    "            'xticklabels': concepts,\n",
    "            'yticklabels': concepts,\n",
    "            'annot': True,\n",
    "            'fmt': '.3f',\n",
    "            'cmap': 'viridis',\n",
    "            'vmin': 0.5, #set vmin and vmax to be consistent and centered\n",
    "            'vmax': 1.0,\n",
    "            'center': 0.75\n",
    "        }\n",
    "\n",
    "        sns.heatmap(train_matrix, ax=ax1, **heatmap_params)\n",
    "        ax1.set_title(f'Training {metric.replace(\"test_\", \"\").replace(\"_\", \" \").title()}') # Dynamic title\n",
    "        ax1.set_xticklabels(ax1.get_xticklabels(), rotation=45, ha='right')\n",
    "\n",
    "        sns.heatmap(test_matrix, ax=ax2, **heatmap_params)\n",
    "        ax2.set_title(f'Test {metric.replace(\"test_\", \"\").replace(\"_\", \" \").title()}') # Dynamic title\n",
    "        ax2.set_xticklabels(ax2.get_xticklabels(), rotation=45, ha='right')\n",
    "\n",
    "        for ax, matrix in [(ax1, train_matrix), (ax2, test_matrix)]:\n",
    "            for i in range(len(concepts)):\n",
    "                for j in range(len(concepts)):\n",
    "                    if np.isnan(matrix[i, j]):\n",
    "                        ax.text(j + 0.5, i + 0.5, 'N/A',\n",
    "                               ha='center', va='center',\n",
    "                               color='gray')\n",
    "        plt.suptitle(f'Train vs Test Performance for Concept Decoding - Patient {self.patient_data.pid}, Epoch: {self.epoch}', y=1.05)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All concept decoding!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing playground\n",
    "\n",
    "\n",
    ":)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Data/40m_act_24_S06E01_30fps_character_frames.csv\n",
      "c1 shape: 20, c2 shape: 68\n",
      "Skipping concept pair A.Amar, B.Buchanan: Insufficient samples for A.Amar vs B.Buchanan\n"
     ]
    }
   ],
   "source": [
    "p563 = PatientData(pid='563')\n",
    "decoder = ConceptDecoder(patient_data=p563, c1='A.Amar', c2='B.Buchanan', epoch='movie')\n",
    "res = decoder.decode()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7407407407407407"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of concept pairs to decode: 10\n",
      "[('A.Amar', 'A.Fayed'), ('A.Amar', 'B.Buchanan'), ('A.Amar', 'C.Manning'), ('A.Amar', 'C.OBrian'), ('A.Fayed', 'B.Buchanan')]\n"
     ]
    }
   ],
   "source": [
    "concept_pairs_to_decode = []\n",
    "concept_list = list(p566.movie_df.columns)\n",
    "#remove non-concept columns if they exist\n",
    "concept_list = [col for col in concept_list if col not in ['Frame', 'time_sec', 'rel_corrected_time_sec', 'uncorrected_time_sec']]\n",
    "\n",
    "\n",
    "# doing to 5 for time\n",
    "\n",
    "for i, concept1 in enumerate(concept_list[:5]):\n",
    "    for concept2 in concept_list[i+1:5]: #avoid duplicates and self-pairs\n",
    "        concept_pairs_to_decode.append((concept1, concept2))\n",
    "\n",
    "print(f\"Number of concept pairs to decode: {len(concept_pairs_to_decode)}\")\n",
    "print(concept_pairs_to_decode[:5]) # Print first 5 pairs as example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = DecodingResultsManager(\n",
    "    patient_data=p566,\n",
    "    concept_pairs=concept_pairs_to_decode,\n",
    "    epoch='movie',\n",
    "    standardize=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c1 shape: 19, c2 shape: 51\n",
      "Skipping concept pair A.Amar, A.Fayed: Insufficient samples for A.Amar vs A.Fayed\n",
      "c1 shape: 20, c2 shape: 68\n",
      "c1 shape: 20, c2 shape: 27\n",
      "c1 shape: 19, c2 shape: 76\n",
      "Skipping concept pair A.Amar, C.OBrian: Insufficient samples for A.Amar vs C.OBrian\n",
      "c1 shape: 52, c2 shape: 63\n",
      "c1 shape: 53, c2 shape: 26\n",
      "c1 shape: 54, c2 shape: 71\n",
      "c1 shape: 55, c2 shape: 10\n",
      "Skipping concept pair B.Buchanan, C.Manning: Insufficient samples for B.Buchanan vs C.Manning\n",
      "c1 shape: 62, c2 shape: 70\n",
      "c1 shape: 27, c2 shape: 74\n"
     ]
    }
   ],
   "source": [
    "manager.run_decoding_for_pairs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib' has no attribute 'subplots'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmanager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_train_test_performance_heatmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest_roc_auc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Example ROC AUC heatmap\u001b[39;00m\n\u001b[1;32m      2\u001b[0m manager\u001b[38;5;241m.\u001b[39mplot_train_test_performance_heatmap(metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# Example Accuracy heatmap\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[16], line 61\u001b[0m, in \u001b[0;36mDecodingResultsManager.plot_train_test_performance_heatmap\u001b[0;34m(self, metric, figsize)\u001b[0m\n\u001b[1;32m     58\u001b[0m         test_matrix[i, j] \u001b[38;5;241m=\u001b[39m test_value\n\u001b[1;32m     59\u001b[0m         test_matrix[j, i] \u001b[38;5;241m=\u001b[39m test_value\n\u001b[0;32m---> 61\u001b[0m fig, (ax1, ax2) \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubplots\u001b[49m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, figsize\u001b[38;5;241m=\u001b[39mfigsize)\n\u001b[1;32m     63\u001b[0m heatmap_params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxticklabels\u001b[39m\u001b[38;5;124m'\u001b[39m: concepts,\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124myticklabels\u001b[39m\u001b[38;5;124m'\u001b[39m: concepts,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcenter\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.75\u001b[39m\n\u001b[1;32m     72\u001b[0m }\n\u001b[1;32m     74\u001b[0m sns\u001b[38;5;241m.\u001b[39mheatmap(train_matrix, ax\u001b[38;5;241m=\u001b[39max1, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mheatmap_params)\n",
      "File \u001b[0;32m~/Desktop/research/.venv/lib/python3.11/site-packages/matplotlib/_api/__init__.py:217\u001b[0m, in \u001b[0;36mcaching_module_getattr.<locals>.__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m props:\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m props[name]\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance)\n\u001b[0;32m--> 217\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'matplotlib' has no attribute 'subplots'"
     ]
    }
   ],
   "source": [
    "manager.plot_train_test_performance_heatmap(metric='test_roc_auc') # Example ROC AUC heatmap\n",
    "manager.plot_train_test_performance_heatmap(metric='test_accuracy') # Example Accuracy heatmap"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
